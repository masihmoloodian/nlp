{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gV9WWMu1DYy"
   },
   "source": [
    "Fusion in Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "A66fGlY-sX8r"
   },
   "outputs": [],
   "source": [
    "def normalize_scores(scores: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Normalize a dictionary of scores to the range [0, 1].\n",
    "\n",
    "    The normalization is performed using the formula:\n",
    "    normalized_score = (score - min_score) / (max_score - min_score)\n",
    "    \"\"\"\n",
    "    min_score = min(scores.values())\n",
    "    max_score = max(scores.values())\n",
    "\n",
    "    return {\n",
    "        doc: (score - min_score) / (max_score - min_score) if max_score > min_score else 0\n",
    "        for doc, score in scores.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "XNxl2-jpumKH"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "def fusion(results: List[Dict[str, float]]) -> List[Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    Fuse multiple result sets by normalizing their scores, aggregating them,\n",
    "    and returning a ranked list of documents based on combined scores.\n",
    "    \"\"\"\n",
    "    normalized_results = [normalize_scores(result) for result in results]\n",
    "\n",
    "    combined_scores = defaultdict(float)\n",
    "    for norm_result in normalized_results:\n",
    "        for doc, score in norm_result.items():\n",
    "            combined_scores[doc] += score / len(results)\n",
    "\n",
    "    ranked_docs = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return ranked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0cmZKXTKy4ve",
    "outputId": "a1219b14-172c-427e-8d53-9352000860cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Ranking: [('doc2', 0.7307692307692308), ('doc1', 0.5), ('doc4', 0.24999999999999986), ('doc3', 0.0)]\n"
     ]
    }
   ],
   "source": [
    "# Example inputs\n",
    "bm25_results = {'doc1': 2.5, 'doc2': 1.8, 'doc3': 1.2}\n",
    "vector_similarity_results = {'doc2': 0.8, 'doc4': 0.7, 'doc1': 0.6}\n",
    "\n",
    "# Fusion\n",
    "final_ranking = fusion([bm25_results, vector_similarity_results])\n",
    "\n",
    "# Output final ranked documents\n",
    "print(\"Final Ranking:\", final_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2IC2CyJry5I8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
